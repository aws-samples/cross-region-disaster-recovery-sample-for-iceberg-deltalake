{
	"metadata": {
		"kernelspec": {
			"name": "glue_pyspark",
			"display_name": "Glue PySpark",
			"language": "python"
		},
		"language_info": {
			"name": "Python_Glue_Session",
			"mimetype": "text/x-python",
			"codemirror_mode": {
				"name": "python",
				"version": 3
			},
			"pygments_lexer": "python3",
			"file_extension": ".py"
		}
	},
	"nbformat_minor": 4,
	"nbformat": 4,
	"cells": [
		{
			"cell_type": "markdown",
			"source": "####  Run this cell to set up and start your interactive session.\n",
			"metadata": {
				"editable": true,
				"trusted": true
			}
		},
		{
			"cell_type": "code",
			"source": "%idle_timeout 2880\n%glue_version 4.0\n%worker_type G.1X\n%number_of_workers 20\n\n%additional_python_modules delta-spark\n%%configure\n{\n\"conf\":\"spark.sql.extensions=io.delta.sql.DeltaSparkSessionExtension --conf spark.sql.catalog.spark_catalog=org.apache.spark.sql.delta.catalog.DeltaCatalog\",\n\"datalake-formats\":\"delta\"\n}\n",
			"metadata": {
				"trusted": true,
				"editable": true
			},
			"execution_count": 7,
			"outputs": [
				{
					"name": "stdout",
					"text": "Welcome to the Glue Interactive Sessions Kernel\nFor more information on available magic commands, please type %help in any new cell.\n\nPlease view our Getting Started page to access the most up-to-date information on the Interactive Sessions kernel: https://docs.aws.amazon.com/glue/latest/dg/interactive-sessions.html\nInstalled kernel version: 1.0.5 \nCurrent idle_timeout is None minutes.\nidle_timeout has been set to 2880 minutes.\nSetting Glue version to: 4.0\nPrevious worker type: None\nSetting new worker type to: G.1X\nPrevious number of workers: None\nSetting new number of workers to: 20\nAdditional python modules to be included:\ndelta-spark\nThe following configurations have been updated: {'conf': 'spark.sql.extensions=io.delta.sql.DeltaSparkSessionExtension --conf spark.sql.catalog.spark_catalog=org.apache.spark.sql.delta.catalog.DeltaCatalog', 'datalake-formats': 'delta'}\n",
					"output_type": "stream"
				}
			]
		},
		{
			"cell_type": "code",
			"source": "import sys\nimport json \nfrom awsglue.transforms import *\nfrom awsglue.utils import getResolvedOptions\nfrom pyspark.context import SparkContext\nfrom awsglue.context import GlueContext\nfrom awsglue.job import Job\n# load spark functions, types\nfrom pyspark.sql.types import *\nfrom pyspark.sql.functions import *\nfrom pyspark.sql import SparkSession\nfrom delta.tables import *\n  \nsc = SparkContext.getOrCreate()\nglueContext = GlueContext(sc)\nspark = glueContext.spark_session\njob = Job(glueContext)",
			"metadata": {
				"trusted": true,
				"tags": []
			},
			"execution_count": 1,
			"outputs": [
				{
					"name": "stdout",
					"text": "Trying to create a Glue session for the kernel.\nSession Type: glueetl\nWorker Type: G.1X\nNumber of Workers: 20\nIdle Timeout: 2880\nSession ID: a6d3a1a5-7533-42b5-995d-09ef3bddd873\nApplying the following default arguments:\n--glue_kernel_version 1.0.5\n--enable-glue-datacatalog true\n--conf spark.sql.extensions=io.delta.sql.DeltaSparkSessionExtension --conf spark.sql.catalog.spark_catalog=org.apache.spark.sql.delta.catalog.DeltaCatalog\n--datalake-formats delta\n--additional-python-modules delta-spark\nWaiting for session a6d3a1a5-7533-42b5-995d-09ef3bddd873 to get into ready status...\nSession a6d3a1a5-7533-42b5-995d-09ef3bddd873 has been created.\n\n",
					"output_type": "stream"
				}
			]
		},
		{
			"cell_type": "code",
			"source": "bucket_name = \"delta-poc-primary-061588638285\"\nbucket_prefix = \"\"\ndatabase_name = \"delta_poc\"\ndatabase_prefix = f\"{bucket_prefix}/{database_name}\"\ndatabase_location = f\"s3://{bucket_name}/{database_prefix}/\"\ntable_name = \"customers\"\ntable_prefix = f\"{database_prefix}/{table_name}\"\ntable_location = f\"s3://{bucket_name}/{table_prefix}/\"",
			"metadata": {
				"trusted": true,
				"tags": []
			},
			"execution_count": 2,
			"outputs": [
				{
					"name": "stdout",
					"text": "\n",
					"output_type": "stream"
				}
			]
		},
		{
			"cell_type": "code",
			"source": "spark.sql(f\"CREATE DATABASE {database_name} LOCATION '{table_location}'\")",
			"metadata": {
				"trusted": true,
				"tags": []
			},
			"execution_count": 3,
			"outputs": [
				{
					"name": "stdout",
					"text": "DataFrame[]\n",
					"output_type": "stream"
				}
			]
		},
		{
			"cell_type": "code",
			"source": "# Define the schema of the raw customer table\ncustomer_schema = StructType(\n            [ StructField(\"c_customer_sk\",IntegerType(),True),\n              StructField(\"c_customer_id\",StringType(),True),\n              StructField(\"c_current_cdemo_sk\",IntegerType(),True),\n              StructField(\"c_current_hdemo_sk\",IntegerType(),True),\n              StructField(\"c_current_addr_sk\",IntegerType(),True),\n              StructField(\"c_first_shipto_date_sk\",IntegerType(),True),\n              StructField(\"c_first_sales_date_sk\",IntegerType(),True),\n              StructField(\"c_salutation\",StringType(),True),\n              StructField(\"c_first_name\",StringType(),True),\n              StructField(\"c_last_name\",StringType(),True),\n              StructField(\"c_preferred_cust_flag\",StringType(),True),\n              StructField(\"c_birth_day\",IntegerType(),True),\n              StructField(\"c_birth_month\",IntegerType(),True),\n              StructField(\"c_birth_year\",IntegerType(),True),\n              StructField(\"c_birth_country\", StringType(), True),\n              StructField(\"c_login\", StringType(), True),\n              StructField(\"c_email_address\", StringType(), True),\n              StructField(\"c_last_review_date_sk\", IntegerType(), True)\n              ]\n              )",
			"metadata": {
				"trusted": true,
				"tags": []
			},
			"execution_count": 4,
			"outputs": [
				{
					"name": "stdout",
					"text": "\n",
					"output_type": "stream"
				}
			]
		},
		{
			"cell_type": "code",
			"source": "df_customer = spark.read.schema(customer_schema).\\\n                format(\"csv\").options(header=True,delimiter=\"|\").\\\n                load(\"s3://redshift-downloads/TPC-DS/2.13/100GB/customer/\")\nprint(f'df_customer - rows: {df_customer.count()}, columns: {len(df_customer.columns)}')",
			"metadata": {
				"trusted": true,
				"tags": []
			},
			"execution_count": 5,
			"outputs": [
				{
					"name": "stdout",
					"text": "df_customer - rows: 1999999, columns: 18\n",
					"output_type": "stream"
				}
			]
		},
		{
			"cell_type": "code",
			"source": "df_customer.write.format(\"delta\"). \\\n  mode(\"overwrite\"). \\\n  save(f\"s3://{bucket_name}/{bucket_prefix}{table_name}\")",
			"metadata": {
				"trusted": true,
				"tags": []
			},
			"execution_count": 6,
			"outputs": [
				{
					"name": "stdout",
					"text": "\n",
					"output_type": "stream"
				}
			]
		},
		{
			"cell_type": "code",
			"source": "f\"s3://{bucket_name}/{bucket_prefix}{table_name}/\"",
			"metadata": {
				"trusted": true,
				"tags": []
			},
			"execution_count": 8,
			"outputs": [
				{
					"name": "stdout",
					"text": "'s3://delta-poc-primary-061588638285/customers/'\n",
					"output_type": "stream"
				}
			]
		},
		{
			"cell_type": "code",
			"source": "# create table in metastore\nquery = f\"\"\"\nCREATE TABLE {database_name}.{table_name}\nUSING delta\nLOCATION 's3://delta-poc-primary-061588638285/customers/'\n\"\"\"\n\nspark.sql(query)",
			"metadata": {
				"trusted": true,
				"tags": []
			},
			"execution_count": 9,
			"outputs": [
				{
					"name": "stdout",
					"text": "DataFrame[]\n",
					"output_type": "stream"
				}
			]
		},
		{
			"cell_type": "code",
			"source": "%%sql\nUSE delta_poc",
			"metadata": {
				"trusted": true,
				"tags": []
			},
			"execution_count": 10,
			"outputs": [
				{
					"name": "stdout",
					"text": "++\n||\n++\n++\n",
					"output_type": "stream"
				}
			]
		},
		{
			"cell_type": "code",
			"source": "%%sql\nSHOW TABLES;",
			"metadata": {
				"trusted": true,
				"tags": []
			},
			"execution_count": 11,
			"outputs": [
				{
					"name": "stdout",
					"text": "+---------+---------+-----------+\n|namespace|tableName|isTemporary|\n+---------+---------+-----------+\n|delta_poc|customers|      false|\n+---------+---------+-----------+\n",
					"output_type": "stream"
				}
			]
		},
		{
			"cell_type": "code",
			"source": "deltaTable = DeltaTable.forPath(spark, 's3://delta-poc-primary-061588638285/customers/')",
			"metadata": {
				"trusted": true,
				"tags": []
			},
			"execution_count": 15,
			"outputs": [
				{
					"name": "stdout",
					"text": "\n",
					"output_type": "stream"
				}
			]
		},
		{
			"cell_type": "code",
			"source": "fullHistoryDF = deltaTable.history()   # display the table history\nfullHistoryDF.show()",
			"metadata": {
				"trusted": true,
				"tags": []
			},
			"execution_count": 16,
			"outputs": [
				{
					"name": "stdout",
					"text": "+-------+-------------------+------+--------+---------+--------------------+----+--------+---------+-----------+--------------+-------------+--------------------+------------+--------------------+\n|version|          timestamp|userId|userName|operation| operationParameters| job|notebook|clusterId|readVersion|isolationLevel|isBlindAppend|    operationMetrics|userMetadata|          engineInfo|\n+-------+-------------------+------+--------+---------+--------------------+----+--------+---------+-----------+--------------+-------------+--------------------+------------+--------------------+\n|      0|2024-09-04 18:04:38|  null|    null|    WRITE|{mode -> Overwrit...|null|    null|     null|       null|  Serializable|        false|{numFiles -> 1, n...|        null|Apache-Spark/3.3....|\n+-------+-------------------+------+--------+---------+--------------------+----+--------+---------+-----------+--------------+-------------+--------------------+------------+--------------------+\n",
					"output_type": "stream"
				}
			]
		},
		{
			"cell_type": "code",
			"source": "df_customer_100B = spark.read.schema(customer_schema).\\\n                format(\"csv\").options(header=True,delimiter=\"|\").\\\n                load(\"s3://redshift-downloads/TPC-DS/1TB/customer/\")\n",
			"metadata": {
				"trusted": true,
				"tags": []
			},
			"execution_count": 17,
			"outputs": [
				{
					"name": "stdout",
					"text": "\n",
					"output_type": "stream"
				}
			]
		},
		{
			"cell_type": "code",
			"source": "print(f'df_customer - rows: {df_customer_100B.count()}, columns: {len(df_customer_100B.columns)}')",
			"metadata": {
				"trusted": true,
				"tags": []
			},
			"execution_count": 18,
			"outputs": [
				{
					"name": "stdout",
					"text": "df_customer - rows: 11999960, columns: 18\n",
					"output_type": "stream"
				}
			]
		},
		{
			"cell_type": "code",
			"source": "df_customer_100B.write.format(\"delta\"). \\\n  mode(\"append\"). \\\n  save(f\"s3://{bucket_name}/{bucket_prefix}/{table_name}\")",
			"metadata": {
				"trusted": true,
				"tags": []
			},
			"execution_count": 19,
			"outputs": [
				{
					"name": "stdout",
					"text": "\n",
					"output_type": "stream"
				}
			]
		},
		{
			"cell_type": "code",
			"source": "11999960+1999999 =  13999959",
			"metadata": {
				"trusted": true,
				"tags": []
			},
			"execution_count": 34,
			"outputs": [
				{
					"name": "stdout",
					"text": "13999959\n",
					"output_type": "stream"
				}
			]
		},
		{
			"cell_type": "code",
			"source": "fullHistoryDF = deltaTable.history()   # display the table history\nfullHistoryDF.show()",
			"metadata": {
				"trusted": true,
				"tags": []
			},
			"execution_count": 20,
			"outputs": [
				{
					"name": "stdout",
					"text": "+-------+-------------------+------+--------+---------+--------------------+----+--------+---------+-----------+--------------+-------------+--------------------+------------+--------------------+\n|version|          timestamp|userId|userName|operation| operationParameters| job|notebook|clusterId|readVersion|isolationLevel|isBlindAppend|    operationMetrics|userMetadata|          engineInfo|\n+-------+-------------------+------+--------+---------+--------------------+----+--------+---------+-----------+--------------+-------------+--------------------+------------+--------------------+\n|      1|2024-09-04 18:07:32|  null|    null|    WRITE|{mode -> Append, ...|null|    null|     null|          0|  Serializable|         true|{numFiles -> 40, ...|        null|Apache-Spark/3.3....|\n|      0|2024-09-04 18:04:38|  null|    null|    WRITE|{mode -> Overwrit...|null|    null|     null|       null|  Serializable|        false|{numFiles -> 1, n...|        null|Apache-Spark/3.3....|\n+-------+-------------------+------+--------+---------+--------------------+----+--------+---------+-----------+--------------+-------------+--------------------+------------+--------------------+\n",
					"output_type": "stream"
				}
			]
		},
		{
			"cell_type": "code",
			"source": "update_Df = df_customer.filter(df_customer.c_birth_country=='UNITED STATES')",
			"metadata": {
				"trusted": true,
				"tags": []
			},
			"execution_count": 21,
			"outputs": [
				{
					"name": "stdout",
					"text": "\n",
					"output_type": "stream"
				}
			]
		},
		{
			"cell_type": "code",
			"source": "update_Df = update_Df.withColumn(\"c_birth_country\",lit(\"US\"))",
			"metadata": {
				"trusted": true,
				"tags": []
			},
			"execution_count": 22,
			"outputs": [
				{
					"name": "stdout",
					"text": "\n",
					"output_type": "stream"
				}
			]
		},
		{
			"cell_type": "code",
			"source": "update_Df.select(['c_customer_id']).distinct().count()",
			"metadata": {
				"trusted": true,
				"tags": []
			},
			"execution_count": 23,
			"outputs": [
				{
					"name": "stdout",
					"text": "9206\n",
					"output_type": "stream"
				}
			]
		},
		{
			"cell_type": "code",
			"source": "deltaTable.alias(\"events\").merge(\n    update_Df.alias(\"updates\"),\n    \"events.c_customer_id = updates.c_customer_id\") \\\n  .whenMatchedUpdate(set = { \"c_birth_country\" : \"updates.c_birth_country\" } ) \\\n  .execute()",
			"metadata": {
				"trusted": true,
				"tags": []
			},
			"execution_count": 24,
			"outputs": [
				{
					"name": "stdout",
					"text": "\n",
					"output_type": "stream"
				}
			]
		},
		{
			"cell_type": "code",
			"source": "fullHistoryDF = deltaTable.history()   # display the table history\nfullHistoryDF.show()",
			"metadata": {
				"trusted": true,
				"tags": []
			},
			"execution_count": 25,
			"outputs": [
				{
					"name": "stdout",
					"text": "+-------+-------------------+------+--------+---------+--------------------+----+--------+---------+-----------+--------------+-------------+--------------------+------------+--------------------+\n|version|          timestamp|userId|userName|operation| operationParameters| job|notebook|clusterId|readVersion|isolationLevel|isBlindAppend|    operationMetrics|userMetadata|          engineInfo|\n+-------+-------------------+------+--------+---------+--------------------+----+--------+---------+-----------+--------------+-------------+--------------------+------------+--------------------+\n|      2|2024-09-04 18:09:13|  null|    null|    MERGE|{predicate -> (ev...|null|    null|     null|          1|  Serializable|        false|{numTargetRowsCop...|        null|Apache-Spark/3.3....|\n|      1|2024-09-04 18:07:32|  null|    null|    WRITE|{mode -> Append, ...|null|    null|     null|          0|  Serializable|         true|{numFiles -> 40, ...|        null|Apache-Spark/3.3....|\n|      0|2024-09-04 18:04:38|  null|    null|    WRITE|{mode -> Overwrit...|null|    null|     null|       null|  Serializable|        false|{numFiles -> 1, n...|        null|Apache-Spark/3.3....|\n+-------+-------------------+------+--------+---------+--------------------+----+--------+---------+-----------+--------------+-------------+--------------------+------------+--------------------+\n",
					"output_type": "stream"
				}
			]
		},
		{
			"cell_type": "code",
			"source": "deltaTable.delete(\"c_birth_country is null\")  #498624",
			"metadata": {
				"trusted": true,
				"tags": []
			},
			"execution_count": 27,
			"outputs": [
				{
					"name": "stdout",
					"text": "\n",
					"output_type": "stream"
				}
			]
		},
		{
			"cell_type": "code",
			"source": "df = deltaTable.optimize().executeCompaction()",
			"metadata": {
				"trusted": true,
				"tags": []
			},
			"execution_count": 28,
			"outputs": [
				{
					"name": "stdout",
					"text": "\n",
					"output_type": "stream"
				}
			]
		},
		{
			"cell_type": "code",
			"source": "df.show(truncate=False)",
			"metadata": {
				"trusted": true,
				"tags": []
			},
			"execution_count": 31,
			"outputs": [
				{
					"name": "stdout",
					"text": "+---------------------------------------------+-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n|path                                         |metrics                                                                                                                                                                              |\n+---------------------------------------------+-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n|s3://delta-poc-primary-061588638285/customers|{1, 41, {729470213, 729470213, 7.29470213E8, 1, 729470213}, {4916639, 105952518, 1.7894429756097563E7, 41, 733671620}, 1, null, 1, 41, 0, false, 0, 0, 1725473499419, 0, 76, 0, null}|\n+---------------------------------------------+-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n",
					"output_type": "stream"
				}
			]
		},
		{
			"cell_type": "code",
			"source": "fullHistoryDF = deltaTable.history()   # display the table history\nfullHistoryDF.show()",
			"metadata": {
				"trusted": true,
				"tags": []
			},
			"execution_count": 32,
			"outputs": [
				{
					"name": "stdout",
					"text": "+-------+-------------------+------+--------+---------+--------------------+----+--------+---------+-----------+-----------------+-------------+--------------------+------------+--------------------+\n|version|          timestamp|userId|userName|operation| operationParameters| job|notebook|clusterId|readVersion|   isolationLevel|isBlindAppend|    operationMetrics|userMetadata|          engineInfo|\n+-------+-------------------+------+--------+---------+--------------------+----+--------+---------+-----------+-----------------+-------------+--------------------+------------+--------------------+\n|      4|2024-09-04 18:11:39|  null|    null| OPTIMIZE|{predicate -> [],...|null|    null|     null|          3|SnapshotIsolation|        false|{numRemovedFiles ...|        null|Apache-Spark/3.3....|\n|      3|2024-09-04 18:09:57|  null|    null|   DELETE|{predicate -> [\"(...|null|    null|     null|          2|     Serializable|        false|{numRemovedFiles ...|        null|Apache-Spark/3.3....|\n|      2|2024-09-04 18:09:13|  null|    null|    MERGE|{predicate -> (ev...|null|    null|     null|          1|     Serializable|        false|{numTargetRowsCop...|        null|Apache-Spark/3.3....|\n|      1|2024-09-04 18:07:32|  null|    null|    WRITE|{mode -> Append, ...|null|    null|     null|          0|     Serializable|         true|{numFiles -> 40, ...|        null|Apache-Spark/3.3....|\n|      0|2024-09-04 18:04:38|  null|    null|    WRITE|{mode -> Overwrit...|null|    null|     null|       null|     Serializable|        false|{numFiles -> 1, n...|        null|Apache-Spark/3.3....|\n+-------+-------------------+------+--------+---------+--------------------+----+--------+---------+-----------+-----------------+-------------+--------------------+------------+--------------------+\n",
					"output_type": "stream"
				}
			]
		},
		{
			"cell_type": "code",
			"source": "spark.conf.set(\"spark.databricks.delta.retentionDurationCheck.enabled\", \"false\")\ndeltaTable.vacuum(0)",
			"metadata": {
				"trusted": true,
				"tags": []
			},
			"execution_count": 33,
			"outputs": [
				{
					"name": "stdout",
					"text": "DataFrame[]\n",
					"output_type": "stream"
				}
			]
		}
	]
}
